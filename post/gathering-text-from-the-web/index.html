<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Gathering Text from the Web - Dr. Erin Buchanan</title>
  <meta name="description" content="Hi everyone! I don&rsquo;t really feel like working too hard today, so I decided to write a blog post about how my student Will and I used rvest to mine articles from several different news sources for a project. All the scripts and current ongoings of this project can be found on our OSF page - this project is also connected to the GitHub folder with the files.
First, we picked four web sources to scrape - The New York Times, NPR, Fox News, and Breitbart because of their known political associations, and specifically, we focused on their political sections."><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Dr. Erin Buchanan",
    
    "url": "https:\/\/doomlab.github.io"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "https:\/\/doomlab.github.io"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "https:\/\/doomlab.github.io",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "https:\/\/doomlab.github.io\/post\/gathering-text-from-the-web\/",
          "name": "Gathering text from the web"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Erin M. Buchanan"
  },
  "headline": "Gathering Text from the Web",
  "description" : "Hi everyone! I don\u0026rsquo;t really feel like working too hard today, so I decided to write a blog post about how my student Will and I used rvest to mine articles from several different news sources for a project. All the scripts and current ongoings of this project can be found on our OSF page - this project is also connected to the GitHub folder with the files.\nFirst, we picked four web sources to scrape - The New York Times, NPR, Fox News, and Breitbart because of their known political associations, and specifically, we focused on their political sections.",
  "inLanguage" : "en",
  "wordCount":  1099 ,
  "datePublished" : "2018-05-07T00:00:00",
  "dateModified" : "2018-05-07T00:00:00",
  "image" : "https:\/\/doomlab.github.io\/img\/header.jpg",
  "keywords" : [ "rstudio, rvest, text processing" ],
  "mainEntityOfPage" : "https:\/\/doomlab.github.io\/post\/gathering-text-from-the-web\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "https:\/\/doomlab.github.io",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "https:\/\/doomlab.github.io\/img\/header.jpg",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Gathering Text from the Web" />
<meta property="og:description" content="Hi everyone! I don&rsquo;t really feel like working too hard today, so I decided to write a blog post about how my student Will and I used rvest to mine articles from several different news sources for a project. All the scripts and current ongoings of this project can be found on our OSF page - this project is also connected to the GitHub folder with the files.
First, we picked four web sources to scrape - The New York Times, NPR, Fox News, and Breitbart because of their known political associations, and specifically, we focused on their political sections.">
<meta property="og:image" content="https://doomlab.github.io/img/header.jpg" />
<meta property="og:url" content="https://doomlab.github.io/post/gathering-text-from-the-web/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Dr. Erin Buchanan" />

  <meta name="twitter:title" content="Gathering Text from the Web" />
  <meta name="twitter:description" content="Hi everyone! I don&rsquo;t really feel like working too hard today, so I decided to write a blog post about how my student Will and I used rvest to mine articles from several different news sources â€¦">
  <meta name="twitter:image" content="https://doomlab.github.io/img/header.jpg" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='https://doomlab.github.io/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.120.4">
  <link rel="alternate" href="https://doomlab.github.io/index.xml" type="application/rss+xml" title="Dr. Erin Buchanan"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous"><link rel="stylesheet" href="https://doomlab.github.io/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="https://doomlab.github.io/css/highlight.min.css" /><link rel="stylesheet" href="https://doomlab.github.io/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="https://doomlab.github.io">Dr. Erin Buchanan</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent">Blog</a>
              <div class="navlinks-children">
                
                  <a href="/post">Blog</a>
                
                  <a href="/tags">Tags</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="Stats" href="/page/stats/">Stats</a>
            </li>
          
        
          
            <li>
              <a title="Shiny" href="/shiny/">Shiny</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent">Vita</a>
              <div class="navlinks-children">
                
                  <a href="/page/basics">Basics</a>
                
                  <a href="/page/honors">Honors</a>
                
                  <a href="/page/res_overview">Research Overview</a>
                
                  <a href="/page/res_pubs">Pubs</a>
                
                  <a href="/page/res_grants">Grants</a>
                
                  <a href="/page/res_pres">Pres</a>
                
                  <a href="/page/teach_overview">Teaching Overview</a>
                
                  <a href="/page/students">Students</a>
                
                  <a href="/page/service">Service</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="OSF" href="https://osf.io/4ivpc/">OSF</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Dr. Erin Buchanan" href="https://doomlab.github.io">
            <img class="avatar-img" src="https://doomlab.github.io/img/header.jpg" alt="Dr. Erin Buchanan" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Gathering Text from the Web</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on May 7, 2018
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;6&nbsp;minutes
  
  
  
    
      &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Erin M. Buchanan
    
  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>Hi everyone! I don&rsquo;t really feel like working too hard today, so I decided to write a blog post about how my student <a href="https://williampadfield.wordpress.com/">Will</a> and I used <code>rvest</code> to mine articles from several different news sources for a project. All the scripts and current ongoings of this project can be found <a href="https://osf.io/5kpj7/">on our OSF page</a> - this project is also connected to the <a href="https://github.com/doomlab/Will-Pilot">GitHub folder</a> with the files.</p>
<p>First, we picked four web sources to scrape - The New York Times, NPR, Fox News, and Breitbart because of their known political associations, and specifically, we focused on their political sections. To get started, you need the <code>rvest</code> library. After you load the library, you can set your url that you want to pull articles from.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">library(rvest)
</span></span><span class="line"><span class="cl">#Specifying the url for desired website to be scrapped
</span></span><span class="line"><span class="cl">url &lt;- &#39;https://www.nytimes.com/section/politics&#39;
</span></span></code></pre></div><p>Now, this url is just where we expect to find a list of links to open for each individual article that was written by the Times. In many <code>rvest</code> tutorials, they focus on pulling only the information from one page - in this blog, I am showing you how to use loops to pull a bunch of separate pages/posts - this tutorial would also work well for pulling from blog type pages.</p>
<p>Next, we read in the main webpage:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">#Reading the HTML code from the website - headlines
</span></span><span class="line"><span class="cl">webpage &lt;- read_html(url)
</span></span><span class="line"><span class="cl">headline_data &lt;- html_nodes(webpage,&#39;.story-link a, .story-body a&#39;)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&gt; headline_data
</span></span><span class="line"><span class="cl">{xml_nodeset (48)}
</span></span><span class="line"><span class="cl"> [1] &lt;a href=&#34;https://www.n ...
</span></span><span class="line"><span class="cl"> [2] &lt;a href=&#34;https://www.n ...
</span></span><span class="line"><span class="cl"> [3] &lt;a href=&#34;https://www.n ...
</span></span></code></pre></div><p>Specifically, <code>read_html</code> pulled in the entire webpage, and the <code>html_nodes</code> function helped us find what we were looking for. In this part, we used the <a href="http://selectorgadget.com/">Selector Gadget</a> extension to find the right parts we were looking for. If you know a bit of CSS, you can view page source on your target page, and then find the class/id properties you are searching for. For the non-web people, essentially, this tool allows you to find the specific parts of a website you want to extract. In our case, we were looking for the story headlines and their individual page links <code>a</code> for <code>a href</code>, which is code for links on the web.</p>
<p>From there, we extracted the attributes of the story links, which created a big list of the headlines and other attributes about them. I really only wanted the links to the individual stories though - not all the information about them. <code>html_attrs</code> created mini-lists of all the attributes for each part of the page we had scraped.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">attr_data &lt;- html_attrs(headline_data) 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&gt; attr_data
</span></span><span class="line"><span class="cl">[[1]]
</span></span><span class="line"><span class="cl">                                                                                     href 
</span></span><span class="line"><span class="cl">&#34;https://www.nytimes.com/2018/05/07/us/politics/don-blankenship-trump-west-virginia.html&#34; 
</span></span><span class="line"><span class="cl">                                                                                data-rref 
</span></span><span class="line"><span class="cl">                                                                                       &#34;&#34; 
</span></span></code></pre></div><p>To get only the links, we tried this:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">urlslist &lt;- unlist(attr_data)
</span></span><span class="line"><span class="cl">urlslist &lt;- urlslist[grep(&#34;http&#34;, urlslist)]
</span></span><span class="line"><span class="cl">urlslist &lt;- unique(urlslist)
</span></span><span class="line"><span class="cl">urlslist
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">&gt; urlslist
</span></span><span class="line"><span class="cl"> [1] &#34;https://www.nytimes.com/2018/05/07/us/politics/don-blankenship-trump-west-virginia.html&#34;                               
</span></span><span class="line"><span class="cl"> [2] &#34;https://www.nytimes.com/2018/05/06/us/politics/giuliani-says-trump-would-not-have-to-comply-with-mueller-subpoena.html&#34;
</span></span></code></pre></div><p><code>unlist</code> took out the list of lists and created the attribute data with only one giant vector. Then I used the <code>grep</code> function to find the urls. Therefore, <code>grep(&quot;http&quot;, urslists)</code> returns the vector number of each item with <code>http</code> in it. I wanted the actual urls, not just the item numbers, so I stuck that inside <code>urslist[...]</code>. The <code>unique</code> function was necessary, as links often repeated, and we really only needed them once.</p>
<p>A warning: websites don&rsquo;t always use absolute links. Sometimes they use references to folders or relative links. We found this with two of our sites, and solved that problem in a couple of ways. The solution will depend on how exactly the website references their other pages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">urlslist3 &lt;- urlslist3[grep(&#34;http|.html&#34;, urlslist3)]
</span></span><span class="line"><span class="cl">##fix the ones without the leading foxnews.com
</span></span><span class="line"><span class="cl">urlslist3F &lt;- paste(&#34;http://www.foxnews.com&#34;, urlslist3[grep(&#34;^http&#34;, urlslist3, invert = T)], sep = &#34;&#34;)
</span></span><span class="line"><span class="cl">urlslist3N &lt;- urlslist3[grep(&#34;^http&#34;, urlslist3)]
</span></span><span class="line"><span class="cl">urlslist3 &lt;- c(urlslist3N, urlslist3F)
</span></span><span class="line"><span class="cl">urlslist3 &lt;- unique(urlslist3)
</span></span></code></pre></div><p>On Fox, we could find the urls in our attributes with http OR (that&rsquo;s the pipe <code>|</code>) .html. On Breitbart, we had to use the folder name by doing <code>urlslist4 &lt;- urlslist4[grep(&quot;http|/big-government&quot;, urlslist4)]</code>. Then we created the absolute link by sticking the homepage on the front when necessary with the <code>paste</code> function. The <code>urlslist3N</code> here found all the ones with the http at the front <code>^</code> that we didn&rsquo;t have to fix. Then we combined the fixed and non-fixed ones and found only the unique set.</p>
<p>From there, we started a blank data frame for storing the final data. Then the real magic occurs.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">##start a data frame
</span></span><span class="line"><span class="cl">NYtimesDF &lt;- matrix(NA, nrow = length(urlslist), ncol = 3)
</span></span><span class="line"><span class="cl">colnames(NYtimesDF) &lt;- c(&#34;Source&#34;, &#34;Url&#34;, &#34;Text&#34;)
</span></span><span class="line"><span class="cl">NYtimesDF &lt;- as.data.frame(NYtimesDF)
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">##for loops
</span></span><span class="line"><span class="cl">for (i in 1:length(urlslist)){
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  ##read in the URL
</span></span><span class="line"><span class="cl">  webpage &lt;- read_html(urlslist[i])
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  ##pull the specific nodes
</span></span><span class="line"><span class="cl">  headline_data &lt;- html_nodes(webpage,&#39;.story-content&#39;) 
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  ##pull the text
</span></span><span class="line"><span class="cl">  text_data &lt;- html_text(headline_data)
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  ##save the data
</span></span><span class="line"><span class="cl">  NYtimesDF$Source[i] &lt;- &#34;NY Times&#34;
</span></span><span class="line"><span class="cl">  NYtimesDF$Url[i] &lt;- urlslist[i]
</span></span><span class="line"><span class="cl">  NYtimesDF$Text[i] &lt;- paste(text_data, collapse = &#34;&#34;)
</span></span><span class="line"><span class="cl">    } ##end for loop
</span></span></code></pre></div><p>For a good loop tutorial, see <a href="https://www.r-bloggers.com/how-to-write-the-first-for-loop-in-r/">here</a>. What this code does is loop over the url list you created at the start. For each separate post page it:</p>
<ol>
<li>
<p>pulls in the entire page by reading that one url,</p>
</li>
<li>
<p>pulls out just the story (again figured out with selector gadget how to just get the words instead of headlines this time),</p>
</li>
<li>
<p>uses <code>html_text</code> to get the text in our text section,</p>
</li>
<li>
<p>saves the data for further use. Notice we used <code>paste</code> with the <code>collapse</code> argument to make sure it did not return a list but rather one giant cell of text.</p>
</li>
</ol>
<p>We ran this for <em>DAYS</em> (about twice a day for a month). Websites often use things like &ldquo;see more&rdquo; or &ldquo;older articles&rdquo; to collapse the site - or in the case of Fox (I think), when you scroll paste the current information, more is automatically added (like Facebook). This process saves loading time for the user. We couldn&rsquo;t really force that action to happen from this script, so we simply ran it multiple days to get newer data. The use of unique really allowed us to make sure we weren&rsquo;t getting duplicate data - and if I had to write this again, I would make sure we also pulled in the old data and filtered out more at the beginning rather than the end (but either way works). If you check out our whole script, you can see some other things we did to make this work more efficiently, such as adding all the sub-pages that Fox uses to post politics articles, as they don&rsquo;t all make it to the homepage (or it&rsquo;s going by so fast we weren&rsquo;t getting them even at twice a day).</p>
<p>At the moment, we are still analyzing the data, but the analysis script in our github folder can give you a preview of the next blog post to come about working with text data. Enjoy!</p>


        
          <div class="blog-tags">
            
              <a href="https://doomlab.github.io/tags/rstudio/">rstudio</a>&nbsp;
            
              <a href="https://doomlab.github.io/tags/rvest/">rvest</a>&nbsp;
            
              <a href="https://doomlab.github.io/tags/text-processing/">text processing</a>&nbsp;
            
          </div>
        

        

        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="https://doomlab.github.io/post/new-publication-texting/" data-toggle="tooltip" data-placement="top" title="New Publication: Texting">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="https://doomlab.github.io/post/current-publications-with-papaja/" data-toggle="tooltip" data-placement="top" title="Current Publications with Papaja">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      
        
          
          <div class="disqus-comments">
            <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "aggieerin" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
          </div>
          
        
        
      

    </div>
  </div>
</div>

      
<footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
          
          <li>
            <a href="" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          

          &nbsp;&bull;&nbsp;&copy;
          
            2024
          

          
            &nbsp;&bull;&nbsp;
            <a href="https://doomlab.github.io">Dr. Erin Buchanan</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.120.4</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<script src="https://doomlab.github.io/js/main.js"></script>
<script src="https://doomlab.github.io/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="https://doomlab.github.io/js/load-photoswipe.js"></script>









    
  </body>
</html>

